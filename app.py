
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import tempfile
import seaborn as sns
import matplotlib.pyplot as plt
import pytz
from datetime import datetime
from streamlit.components.v1 import html
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from function_preprocessing_motorbike import preprocess_motobike_data
from build_model_price_anomaly_detection import detect_outliers

st.set_page_config(page_title="Motorbike Price & Anomaly App", layout="wide")

# Báº¯t Ä‘áº§u Ä‘oáº¡n code cáº§n thÃªm Ä‘á»ƒ Ã¡p dá»¥ng justify (cÄƒn Ä‘á»u)
html_code = """
<style>
/* Chá»n táº¥t cáº£ cÃ¡c thÃ nh pháº§n chá»©a vÄƒn báº£n chÃ­nh cá»§a Streamlit
   (nhÆ° st.markdown, st.write, st.header, st.subheader, st.text, v.v.)
   vÃ  Ã¡p dá»¥ng cÄƒn Ä‘á»u (text-align: justify;) */
.stMarkdown, .stText, .stHtml, .stHeader, .stSubheader, .stTitle, .stPageLink, .css-selector-cho-cac-phan-tu-khac {
    text-align: justify;
    text-justify: inter-word; /* DÃ nh cho cÃ¡c trÃ¬nh duyá»‡t IE/Edge */
}
/* Má»™t sá»‘ component nhÆ° st.write/st.markdown sáº½ Ä‘Æ°á»£c bá»c trong class 'stMarkdown'
   vÃ  class nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c bá»c trong cÃ¡c div khÃ¡c. Ta cáº§n selector máº¡nh hÆ¡n. */
div.stMarkdown p, div.stMarkdown, div[data-testid="stText"] {
    text-align: justify;
    text-justify: inter-word;
}
</style>
"""
st.components.v1.html(html_code, height=0)

# 1. Báº®T Äáº¦U: CSS Äá»‚ LOáº I Bá» GIá»šI Háº N CHIá»€U Rá»˜NG Tá»I ÄA Cá»¦A STREAMLIT
# Äáº·t max-width ráº¥t lá»›n (vÃ­ dá»¥: 2000px) Ä‘á»ƒ cho phÃ©p hÃ¬nh áº£nh hiá»ƒn thá»‹ rá»™ng hÆ¡n
html_code_width = """
<style>
/* Loáº¡i bá» giá»›i háº¡n max-width cá»§a khá»‘i ná»™i dung chÃ­nh */
.main .block-container {
    max-width: 2000px !important; 
    padding-left: 1rem;
    padding-right: 1rem;
}
</style>
"""
st.components.v1.html(html_code_width, height=0)
# Káº¾T THÃšC: CSS Äá»‚ LOáº I Bá» GIá»šI Háº N CHIá»€U Rá»˜NG Tá»I ÄA

MODEL_PATH = "motobike_price_prediction_model.pkl"
TRAINING_DATA = "data_motobikes.xlsx"  # optional, used to compute brand_meanprice & grouping to match train

@st.cache_resource
def load_model(path=MODEL_PATH):
    if not os.path.exists(path):
        return None
    with open(path, "rb") as f:
        return pickle.load(f)

@st.cache_data
def build_training_helpers(path=TRAINING_DATA):
    """
    Load training data & build grouping rules + statistical thresholds
    (p10/p90, residual mean/std) for anomaly detection.
    """
    if not os.path.exists(path):
        return None

    try:
        df_train = preprocess_motobike_data(path)
        # =============== LOAD MODELS ===============
        with open("unsup_scaler.pkl", "rb") as f:
            scaler = pickle.load(f)

        with open("kmeans_model.pkl", "rb") as f:
            kmeans = pickle.load(f)

        # =============== 1) BRAND GROUPING ==================
        brand_counts = df_train['brand'].value_counts()
        rare_brands = set(brand_counts[brand_counts < 50].index)

        # model grouping by brand_grouped
        model_group_maps = {}
        for bg, g in df_train.groupby('brand_grouped'):
            counts = g['model'].value_counts()
            rare_models = set(counts[counts < 100].index)
            model_group_maps[bg] = rare_models

        # mean price for brand
        brand_mean_map = df_train.groupby('brand')['brand_meanprice'].first().to_dict()

        # =============== 2) PRICE P10/P90 BY SEGMENT ==================
        seg_price_stats = (
            df_train.groupby('segment')['price']
                    .quantile([0.10, 0.90])
                    .unstack(level=1)
                    .rename(columns={0.10:'p10', 0.90:'p90'})
        ).reset_index()

        seg_price_map = seg_price_stats.set_index('segment').to_dict('index')
        # format: seg_price_map[segment] = {'p10':..., 'p90':...}

        # =============== 3) RESIDUAL STATS BY SEGMENT ==================

        # Load model
        with open(MODEL_PATH, 'rb') as f:
            model = pickle.load(f)

        # Define cols
        cat_cols = ['segment','bike_type','origin','engine_capacity']
        num_cols = ['age','mileage_km','min_price','max_price','brand_meanprice']

        # Build matrix
        X = df_train[cat_cols + num_cols]
        # y = df['log_price']

        # Predict price
        df_train['price_hat'] = np.expm1(model.predict(X))
        df_train['resid'] = df_train['price'] - df_train['price_hat']  # price_hat tá»« preprocess

        seg_resid_stats = (
            df_train.groupby('segment')['resid']
                    .agg(['mean', 'std'])
                    .rename(columns={'mean': 'resid_mean', 'std': 'resid_std'})
        ).reset_index()

        seg_resid_map = seg_resid_stats.set_index('segment').to_dict('index')
        # format: seg_resid_map[seg] = {'resid_mean':..., 'resid_std':...}

        return {
            'rare_brands': rare_brands,
            'model_group_maps': model_group_maps,
            'brand_mean_map': brand_mean_map,
            'seg_price_map': seg_price_map,
            'seg_resid_map': seg_resid_map
        }

    except Exception as e:
        print("Error building helpers:", e)
        return None


helpers = build_training_helpers(TRAINING_DATA)
model = load_model(MODEL_PATH)

st.title("Há»‡ thá»‘ng Dá»± bÃ¡o GiÃ¡ Xe MÃ¡y vÃ  Nháº­n diá»‡n GiÃ¡ Báº¥t ThÆ°á»ng")
# st.markdown("á»¨ng dá»¥ng cho phÃ©p: 1) Dá»± Ä‘oÃ¡n giÃ¡ xe mÃ¡y (nháº­p tay hoáº·c upload file) 2) PhÃ¡t hiá»‡n xe báº¥t thÆ°á»ng (upload file)")
# st.image("xe_may_cu.jpg", caption="Xe mÃ¡y cÅ©")
st.image("xe_may_cu.jpg", caption="Xe mÃ¡y cÅ©", width=1000)

st.sidebar.markdown("**Há»‡ thá»‘ng Dá»± bÃ¡o GiÃ¡ Xe MÃ¡y vÃ  Nháº­n diá»‡n GiÃ¡ Báº¥t ThÆ°á»ng**")

# page = st.sidebar.selectbox("Chá»n chá»©c nÄƒng", ["Dá»± Ä‘oÃ¡n giÃ¡", "PhÃ¡t hiá»‡n báº¥t thÆ°á»ng"])
menu = ["Giá»›i thiá»‡u", "BÃ i toÃ¡n nghiá»‡p vá»¥", "ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh vÃ  BÃ¡o cÃ¡o", "Dá»± Ä‘oÃ¡n giÃ¡", "PhÃ¡t hiá»‡n xe báº¥t thÆ°á»ng"]
page = st.sidebar.selectbox('Menu', menu)


@st.cache_data
def load_reference_data():
    return preprocess_motobike_data(TRAINING_DATA)

df_ref = load_reference_data()
brand_list = sorted(df_ref['brand_grouped'].dropna().unique())
model_list = sorted(df_ref['model_grouped'].dropna().unique())
bike_type_list = sorted(df_ref['bike_type'].dropna().unique())
origin_list = sorted(df_ref['origin'].dropna().unique())
engine_capacity_list = sorted(df_ref['engine_capacity'].dropna().unique())

if page == 'Giá»›i thiá»‡u':

    st.subheader("[Trang chá»§](https://www.chotot.com/)")
    
    st.header('Giá»›i thiá»‡u dá»± Ã¡n')
    st.markdown('''ÄÃ¢y lÃ  dá»± Ã¡n xÃ¢y dá»±ng há»‡ thá»‘ng há»— trá»£ **Ä‘á»‹nh giÃ¡ xe mÃ¡y cÅ©** vÃ  **phÃ¡t hiá»‡n tin Ä‘Äƒng báº¥t thÆ°á»ng** trÃªn ná»n táº£ng *Chá»£ Tá»‘t* - trong khÃ³a Ä‘á»“ Ã¡n tá»‘t nghiá»‡p Data Science and Machine Learning 2024 lá»›p DL07_K308 cá»§a nhÃ³m 6. \nThÃ nh viÃªn nhÃ³m gá»“m cÃ³:
        \n1. VÅ© Thá»‹ Ngá»c Anh \n2. Nguyá»…n Pháº¡m Quá»³nh Anh''')
    
    st.header('Má»¥c tiÃªu cá»§a dá»± Ã¡n')
    # st.text('''1. Táº¡o mÃ´ hÃ¬nh Ä‘á» xuáº¥t xe mÃ¡y tÆ°Æ¡ng tá»± Ä‘á»‘i vá»›i máº«u xe Ä‘Æ°á»£c chá»n hoáº·c tá»« khÃ³a tÃ¬m kiáº¿m do ngÆ°á»i dÃ¹ng cung cáº¥p.\n2. PhÃ¢n khÃºc thá»‹ trÆ°á»ng xe mÃ¡y''')
    st.write("""
    Má»¥c tiÃªu cá»§a dá»± Ã¡n:
    - **TÄƒng cÆ°á»ng minh báº¡ch** thá»‹ trÆ°á»ng xe mÃ¡y cÅ© thÃ´ng qua dá»± bÃ¡o giÃ¡ há»£p lÃ½.
    - **PhÃ¡t hiá»‡n cÃ¡c tin Ä‘Äƒng báº¥t thÆ°á»ng**, giÃºp lá»c ra xe cÃ³ giÃ¡ hoáº·c thÃ´ng tin sai lá»‡ch.
    - **Há»— trá»£ ngÆ°á»i dÃ¹ng** Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh mua/bÃ¡n chÃ­nh xÃ¡c vÃ  tin cáº­y hÆ¡n.
    - **Tá»‘i Æ°u hÃ³a quy trÃ¬nh kiá»ƒm duyá»‡t** thÃ´ng tin trÃªn ná»n táº£ng giao dá»‹ch xe mÃ¡y.
    """)

    st.header('PhÃ¢n cÃ´ng cÃ´ng viá»‡c')

    st.write("""
        - Xá»­ lÃ½ dá»¯ liá»‡u: Ngá»c Anh vÃ  Quá»³nh Anh
        - Dá»± Ä‘oÃ¡n giÃ¡ xe theo phÆ°Æ¡ng phÃ¡p ML truyá»n thá»‘ng: Ngá»c Anh vÃ  Quá»³nh Anh
        - Dá»± Ä‘oÃ¡n giÃ¡ xe theo PySpark: Ngá»c Anh
        - PhÃ¡t hiá»‡n giÃ¡ báº¥t thÆ°á»ng: Ngá»c Anh
        - LÃ m slide: Ngá»c Anh vÃ  Quá»³nh Anh
        - Giao diá»‡n streamlit: Ngá»c Anh

        """)
elif page == 'BÃ i toÃ¡n nghiá»‡p vá»¥':
    st.subheader("[Trang chá»§](https://www.chotot.com/)")

    st.markdown("""

        ### Váº¥n Ä‘á» nghiá»‡p vá»¥
        - GiÃ¡ niÃªm yáº¿t khÃ´ng Ä‘á»“ng nháº¥t, khÃ³ xÃ¡c Ä‘á»‹nh giÃ¡ thá»‹ trÆ°á»ng.
        - Nhiá»u tin Ä‘Äƒng cÃ³ giÃ¡ báº¥t thÆ°á»ng gÃ¢y nhiá»…u dá»¯ liá»‡u.
        - Kiá»ƒm duyá»‡t thá»§ cÃ´ng tá»‘n thá»i gian vÃ  khÃ´ng nháº¥t quÃ¡n.
        - Cáº§n má»™t há»‡ thá»‘ng dá»± bÃ¡o giÃ¡ vÃ  cáº£nh bÃ¡o báº¥t thÆ°á»ng tá»± Ä‘á»™ng.

        ---

        ### BÃ i toÃ¡n Ä‘áº·t ra
        - XÃ¢y dá»±ng mÃ´ hÃ¬nh **Price Prediction**.
        - Thiáº¿t káº¿ mÃ´ hÃ¬nh **Anomaly Detection** (ML-based + Rule-based).
        - Tá»‘i Æ°u quy trÃ¬nh kiá»ƒm duyá»‡t vÃ  nÃ¢ng cao cháº¥t lÆ°á»£ng tin Ä‘Äƒng.

        ---

        ### Pháº¡m vi triá»ƒn khai
        - Tá»‘i Æ°u & chuáº©n hÃ³a dá»¯ liá»‡u thÃ´.
        - Táº¡o Ä‘áº·c trÆ°ng cho mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡.
        - Huáº¥n luyá»‡n mÃ´ hÃ¬nh **Regression** Ä‘á»ƒ Æ°á»›c lÆ°á»£ng giÃ¡ thá»‹ trÆ°á»ng.
        - XÃ¢y dá»±ng há»‡ thá»‘ng gáº¯n cá» báº¥t thÆ°á»ng gá»“m:
        - **Model-based score** (ML)
        - **Business rule score** (Rule-based)
        - Triá»ƒn khai giao diá»‡n demo báº±ng **Streamlit**.

    """)

    # st.header("###Thu tháº­p dá»¯ liá»‡u")

    st.markdown("""  
    ### Thu tháº­p dá»¯ liá»‡u    
    Bá»™ dá»¯ liá»‡u gá»“m **7.208 tin Ä‘Äƒng** vá»›i **18 thuá»™c tÃ­nh** (thÆ°Æ¡ng hiá»‡u, dÃ²ng xe, sá»‘ km, nÄƒm Ä‘Äƒng kÃ½, giÃ¡ niÃªm yáº¿t, mÃ´ táº£â€¦) Ä‘Æ°á»£c thu tháº­p tá»« ná»n táº£ng **Chá»£ Tá»‘t** (trÆ°á»›c ngÃ y 01/07/2025).  

    Bá»™ dá»¯ liá»‡u bao gá»“m cÃ¡c thÃ´ng tin sau:

    - **id**: sá»‘ thá»© tá»± cá»§a sáº£n pháº©m trong bá»™ dá»¯ liá»‡u  
    - **TiÃªu Ä‘á»**: tá»±a Ä‘á» bÃ i Ä‘Äƒng bÃ¡n sáº£n pháº©m  
    - **GiÃ¡**: giÃ¡ bÃ¡n cá»§a xe mÃ¡y  
    - **Khoáº£ng giÃ¡ min**: giÃ¡ sÃ n Æ°á»›c tÃ­nh cá»§a xe mÃ¡y  
    - **Khoáº£ng giÃ¡ max**: giÃ¡ tráº§n Æ°á»›c tÃ­nh cá»§a xe mÃ¡y  
    - **Äá»‹a chá»‰**: Ä‘á»‹a chá»‰ giao dá»‹ch (phÆ°á»ng, quáº­n, thÃ nh phá»‘ Há»“ ChÃ­ Minh)  
    - **MÃ´ táº£ chi tiáº¿t**: mÃ´ táº£ thÃªm vá» sáº£n pháº©m â€” Ä‘áº·c Ä‘iá»ƒm ná»•i báº­t, tÃ¬nh tráº¡ng, thÃ´ng tin khÃ¡c  
    - **ThÆ°Æ¡ng hiá»‡u**: hÃ£ng sáº£n xuáº¥t (Honda, Yamaha, Piaggio, SYMâ€¦)  
    - **DÃ²ng xe**: dÃ²ng xe cá»¥ thá»ƒ (Air Blade, Vespa, Exciter, LEAD, Vario, â€¦)  
    - **NÄƒm Ä‘Äƒng kÃ½**: nÄƒm Ä‘Äƒng kÃ½ láº§n Ä‘áº§u cá»§a xe  
    - **Sá»‘ km Ä‘Ã£ Ä‘i**: sá»‘ kilomet xe Ä‘Ã£ váº­n hÃ nh  
    - **TÃ¬nh tráº¡ng**: tÃ¬nh tráº¡ng hiá»‡n táº¡i (vÃ­ dá»¥: Ä‘Ã£ sá»­ dá»¥ng)  
    - **Loáº¡i xe**: Xe sá»‘, Tay ga, Tay cÃ´n/Moto  
    - **Dung tÃ­ch xe**: dung tÃ­ch xi-lanh (vÃ­ dá»¥: DÆ°á»›i 50cc, 50â€“100cc, 100â€“175cc, â€¦)  
    - **Xuáº¥t xá»©**: quá»‘c gia sáº£n xuáº¥t (Viá»‡t Nam, ÄÃ i Loan, Nháº­t Báº£n, ...)  
    - **ChÃ­nh sÃ¡ch báº£o hÃ nh**: thÃ´ng tin báº£o hÃ nh náº¿u cÃ³  
    - **Trá»ng lÆ°á»£ng**: trá»ng lÆ°á»£ng Æ°á»›c tÃ­nh cá»§a xe  
    - **Href**: Ä‘Æ°á»ng dáº«n tá»›i bÃ i Ä‘Äƒng sáº£n pháº©m  
    """)


elif page == 'ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh vÃ  BÃ¡o cÃ¡o':    
    st.subheader("[Trang chá»§](https://www.chotot.com/)")  

    # df_home = preprocess_motobike_data(TRAINING_DATA)
    # st.subheader("Dá»¯ liá»‡u xe mÃ¡y cÅ© (10 máº«u)")
    # st.dataframe(df_home.head(10))
    # st.subheader("Quy trÃ¬nh thá»±c hiá»‡n")
    st.subheader("I. Thá»‘ng kÃª mÃ´ táº£ sÆ¡ bá»™")

    # st.markdown("""
    # **1. Thá»‘ng kÃª mÃ´ táº£ sÆ¡ bá»™** 
    # """)
    st.markdown("""        
    Bá»™ dá»¯ liá»‡u gá»“m **7.208 tin Ä‘Äƒng** vá»›i **18 thuá»™c tÃ­nh** (thÆ°Æ¡ng hiá»‡u, dÃ²ng xe, sá»‘ km, nÄƒm Ä‘Äƒng kÃ½, giÃ¡ niÃªm yáº¿t, mÃ´ táº£â€¦) Ä‘Æ°á»£c thu tháº­p tá»« ná»n táº£ng **Chá»£ Tá»‘t** (trÆ°á»›c ngÃ y 01/07/2025).  
                """)
    # --- Váº½ biá»ƒu Ä‘á»“ ---

    # # Hiá»ƒn thá»‹ 4 biá»ƒu Ä‘á»“ dáº¡ng lÆ°á»›i 2x2
    # col1, col2 = st.columns(2)
    # with col1:
    #     st.image("brand_grouped_count.png")
    #     st.image("age_bin_stats.png")

    # with col2:
    #     st.image("price_bin_stats.png")
    #     st.image("mileage_bin_stats.png")

    # Äáº·t chiá»u rá»™ng cho tá»«ng hÃ¬nh áº£nh lÃ  500px
    # Tá»•ng chiá»u rá»™ng 2 cá»™t sáº½ lÃ  1000px
    image_width = 500
    
    # Hiá»ƒn thá»‹ 4 biá»ƒu Ä‘á»“ dáº¡ng lÆ°á»›i 2x2
    col1, col2 = st.columns(2)
    with col1:
        st.image("brand_grouped_count.png", width=image_width) # ThÃªm width=500
        st.image("age_bin_stats.png", width=image_width)       # ThÃªm width=500

    with col2:
        st.image("price_bin_stats.png", width=image_width)     # ThÃªm width=500
        st.image("mileage_bin_stats.png", width=image_width)   # ThÃªm width=500

    st.subheader("II. MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ xe mÃ¡y")

    st.markdown("""

    ##### Lá»±a chá»n thuá»™c tÃ­nh           
    Äá»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ xe mÃ¡y, chÃºng tÃ´i Ä‘Ã£ chá»n lá»c cÃ¡c thuá»™c tÃ­nh Ä‘áº§u vÃ o (input features) cÃ³ tÃ­nh cháº¥t dá»± bÃ¡o cao, bao gá»“m: **ThÆ°Æ¡ng hiá»‡u, DÃ²ng xe, Tuá»•i xe, Sá»‘ km Ä‘Ã£ Ä‘i, Loáº¡i xe, Dung tÃ­ch xe, Xuáº¥t xá»©, Khoáº£ng giÃ¡ min,** vÃ  **Khoáº£ng giÃ¡ max**.
                         
    ##### ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
                
    ChÃºng tÃ´i thá»­ nghiá»‡m nhiá»u mÃ´ hÃ¬nh machine learning, bao gá»“m **Random Forest, SVR, Gradient Boosting, Decision Tree** vÃ  **Linear Regression**. Trong sá»‘ Ä‘Ã³, **Random Forest** cho káº¿t quáº£ vÆ°á»£t trá»™i nháº¥t, thá»ƒ hiá»‡n rÃµ qua báº£ng dÆ°á»›i Ä‘Ã¢y:
    ##### ğŸ“Š So sÃ¡nh hiá»‡u quáº£ cÃ¡c mÃ´ hÃ¬nh

    | MÃ´ hÃ¬nh              | RÂ²       | MAE (VNÄ)        | RMSE (VNÄ)       |
    |---------------------|----------|------------------|------------------|
    | **Random Forest**    | 0.888230 | 4,381,802        | 7,635,801        |
    | **SVR**              | 0.871969 | 4,607,752        | 8,172,413        |
    | **Gradient Boosting**| 0.851320 | 4,884,985        | 8,806,793        |
    | **Decision Tree**    | 0.813617 | 5,319,813        | 9,860,408        |
    | **Linear Regression**| 0.731268 | 6,343,373        | 11,840,010       |
    
    """)
    st.image("actual_vs_predicted.png")
    st.markdown("""
    => Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ cho tháº¥y **Random Forest lÃ  mÃ´ hÃ¬nh cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t**. Do Ä‘Ã³, chÃºng tÃ´i lá»±a chá»n Random Forest lÃ m mÃ´ hÃ¬nh chÃ­nh cho bÃ i toÃ¡n **dá»± Ä‘oÃ¡n giÃ¡ xe mÃ¡y**.
                """)
    
    st.subheader("III. MÃ´ hÃ¬nh phÃ¡t hiá»‡n xe báº¥t thÆ°á»ng")

    # st.markdown("""
    #     ###### Há»‡ thá»‘ng phÃ¡t hiá»‡n báº¥t thÆ°á»ng Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn **hai nhÃ³m tiÃªu chÃ­**: **Äiá»ƒm sá»‘ tá»« mÃ´ hÃ¬nh há»c mÃ¡y** (`score_model_based`) vÃ  Äiá»ƒm sá»‘ tá»« logic nghiá»‡p vá»¥** (`score_business_based`) 
    #         """)
    # st.markdown("""
    #     ###### Hai nhÃ³m tiÃªu chÃ­ nÃ y Ä‘Æ°á»£c káº¿t há»£p nháº±m Ä‘áº£m báº£o viá»‡c phÃ¡t hiá»‡n báº¥t thÆ°á»ng vá»«a **khÃ¡ch quan theo mÃ´ hÃ¬nh**, vá»«a **phÃ¹ há»£p thá»±c táº¿ kinh doanh**.   
    #             """)
    st.markdown("""
        ###### Há»‡ thá»‘ng phÃ¡t hiá»‡n báº¥t thÆ°á»ng Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn **hai nhÃ³m tiÃªu chÃ­**:

        * **Äiá»ƒm sá»‘ tá»« mÃ´ hÃ¬nh há»c mÃ¡y** (`score_model_based`): Äáº£m báº£o viá»‡c phÃ¡t hiá»‡n báº¥t thÆ°á»ng mang tÃ­nh **khÃ¡ch quan theo mÃ´ hÃ¬nh**.
        * **Äiá»ƒm sá»‘ tá»« logic nghiá»‡p vá»¥** (`score_business_based`): Äáº£m báº£o viá»‡c phÃ¡t hiá»‡n báº¥t thÆ°á»ng **phÃ¹ há»£p thá»±c táº¿ kinh doanh**.

        Hai nhÃ³m tiÃªu chÃ­ nÃ y Ä‘Æ°á»£c káº¿t há»£p nháº±m mang láº¡i káº¿t quáº£ phÃ¡t hiá»‡n báº¥t thÆ°á»ng toÃ n diá»‡n vÃ  Ä‘Ã¡ng tin cáº­y.
        """)

    st.markdown("""
        #### 1. TiÃªu chÃ­ Ä‘Ã¡nh dáº¥u báº¥t thÆ°á»ng theo Logic Há»c mÃ¡y (`score_model_based`)

        Há»‡ thá»‘ng sá»­ dá»¥ng **bá»‘n tiÃªu chÃ­** chÃ­nh dá»±a trÃªn mÃ´ hÃ¬nh thá»‘ng kÃª vÃ  há»c mÃ¡y Ä‘á»ƒ gÃ¡n Ä‘iá»ƒm báº¥t thÆ°á»ng:

        ---

        ##### 1.1. **`flag_resid` â€“ Dá»±a trÃªn pháº§n dÆ° (Residual Z-score)**
        * **NgÆ°á»¡ng**: ÄÆ°á»£c Ä‘áº·t lÃ  **3**.
        * **ÄÃ¡nh dáº¥u báº¥t thÆ°á»ng**: Náº¿u **Residual Z-score > 3**, `flag_resid = 1`.
        * **BÃ¬nh thÆ°á»ng**: Náº¿u khÃ´ng, `flag_resid = 0`.

        ---

        ##### 1.2. **`flag_minmax` â€“ Dá»±a trÃªn khoáº£ng giÃ¡ há»£p lÃ½**
        * **ÄÃ¡nh dáº¥u báº¥t thÆ°á»ng**: Náº¿u **giÃ¡ niÃªm yáº¿t** náº±m **ngoÃ i khoáº£ng giÃ¡ Min-Max** Ä‘Æ°á»£c khai bÃ¡o, `flag_minmax = 1`.
        * **BÃ¬nh thÆ°á»ng**: Náº¿u khÃ´ng, `flag_minmax = 0`.

        ---

        ##### 1.3. **`flag_p10p90` â€“ Dá»±a trÃªn PhÃ¢n vá»‹ theo PhÃ¢n khÃºc**
        * **CÆ¡ sá»Ÿ**: XÃ¡c Ä‘á»‹nh **PhÃ¢n vá»‹ 10% (P10)** vÃ  **90% (P90)** cá»§a giÃ¡ xe trong tá»«ng phÃ¢n khÃºc.
        * **ÄÃ¡nh dáº¥u báº¥t thÆ°á»ng**: Náº¿u giÃ¡ trá»‹ náº±m **ngoÃ i khoáº£ng P10â€“P90**, `flag_p10p90 = 1`.
        * **BÃ¬nh thÆ°á»ng**: Náº¿u khÃ´ng, `flag_p10p90 = 0`.

        ---

        ##### 1.4. **`flag_unsup` â€“ Tá»•ng há»£p tá»« Há»c mÃ¡y khÃ´ng giÃ¡m sÃ¡t**
        * **MÃ´ hÃ¬nh**: Káº¿t há»£p káº¿t quáº£ tá»« ba mÃ´ hÃ¬nh chÃ­nh: **Isolation Forest, Local Outlier Factor, vÃ  KMeans**.
        * **TiÃªu chÃ­ KMeans**: Äiá»ƒm báº¥t thÆ°á»ng cÃ³ sá»‘ Ä‘iá»ƒm trong cá»¥m nhá» hÆ¡n 10% tá»•ng thá»ƒ hoáº·c náº±m trong 5% Ä‘iá»ƒm xa tÃ¢m cá»¥m nháº¥t.
        * **ÄÃ¡nh dáº¥u báº¥t thÆ°á»ng**: Náº¿u **hai trong ba** mÃ´ hÃ¬nh trÃªn Ä‘Ã¡nh dáº¥u báº¥t thÆ°á»ng, `flag_unsup = 1`.

        ---

        ##### ğŸ“ˆ TÃ­nh toÃ¡n `score_model_based`
        Äiá»ƒm logic theo mÃ´ hÃ¬nh (`score_model_based`) lÃ  tá»•ng cÃ³ trá»ng sá»‘ cá»§a 4 tiÃªu chÃ­ trÃªn, trong Ä‘Ã³ **`flag_resid`** cÃ³ **trá»ng sá»‘ 0.4**, vÃ  cÃ¡c tiÃªu chÃ­ cÃ²n láº¡i cÃ³ trá»ng sá»‘ **0.2**.

        ---

        #### 2. TiÃªu chÃ­ Ä‘Ã¡nh dáº¥u báº¥t thÆ°á»ng theo Logic Nghiá»‡p vá»¥ (`score_business_based`)

        TiÃªu chÃ­ nÃ y táº­p trung vÃ o sá»± báº¥t thÆ°á»ng cá»§a má»‘i quan há»‡ giá»¯a **Sá»‘ km Ä‘Ã£ Ä‘i** vÃ  **Tuá»•i xe**:

        * **Nghi váº¥n Tua cÃ´ng-tÆ¡-mÃ©t (QuÃ¡ tháº¥p)**: Náº¿u **Sá»‘ km Ä‘Ã£ Ä‘i < 200 * Tuá»•i xe**.
        * **Sá»‘ km cao báº¥t thÆ°á»ng (Khai thÃ¡c/Khai bÃ¡o sai)**: Náº¿u **Sá»‘ km Ä‘Ã£ Ä‘i > 20000 * Tuá»•i xe**.

        ---

        #### 3. Tá»•ng há»£p vÃ  ÄÃ¡nh dáº¥u cuá»‘i cÃ¹ng

        * **Äiá»ƒm tá»•ng há»£p cuá»‘i cÃ¹ng (`final_score`)** lÃ  tá»•ng cá»§a hai Ä‘iá»ƒm: **`score_model_based`** vÃ  **`score_business_based`**.
        * **ÄÃ¡nh dáº¥u Báº¥t thÆ°á»ng**: Xe cÃ³ tá»•ng Ä‘iá»ƒm **lá»›n hÆ¡n 50** sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u lÃ  **Báº¥t thÆ°á»ng**.
        """)

    st.markdown("##### VÃ­ dá»¥ 10 máº«u xe báº¥t thÆ°á»ng Ä‘Æ°á»£c phÃ¡t hiá»‡n:")
    rename_vn = {
    "price": "gia",
    "min_price": "gia_min",
    "max_price": "gia_max",
    "brand": "thuong_hieu",
    "model": "dong_xe",
    "registration_year": "nam_dang_ky",
    "mileage_km": "so_km_da_di",
    "condition": "tinh_trang",
    "bike_type": "loai_xe",
    "engine_capacity": "dung_tich",
    "origin": "xuat_xu",
    "age": "tuoi_xe",
    "score_model_based": "diem_mo_hinh",
    "score_business_based": "diem_nghiep_vu",
    "final_score": "tong_diem",
    "is_outlier": "la_bat_thuong",
    }

    cols_user = [
    "price", "min_price", "max_price",
    "brand", "model", "registration_year", "mileage_km",
    "condition", "bike_type", "engine_capacity", "origin", "age",
    
    # Bá»• sung
    "score_model_based",
    "score_business_based",
    "final_score",
    "is_outlier"
]
    
    df_anomaly = pd.read_csv("outliers_detected_full.csv")
    df_anomaly = df_anomaly[cols_user].rename(columns=rename_vn)
    st.dataframe(df_anomaly.sort_values('tong_diem', ascending=False).head(10))
    
elif page == "Dá»± Ä‘oÃ¡n giÃ¡":

    # --- PREDICTION PAGE ---

    st.header("Dá»± Ä‘oÃ¡n giÃ¡ xe mÃ¡y")

    mode = st.radio("Chá»n cÃ¡ch input:", ["Nháº­p tay má»™t xe", "Upload file (Excel/CSV) Ä‘á»ƒ dá»± Ä‘oÃ¡n nhiá»u xe)"])

    if mode == "Nháº­p tay má»™t xe":
        col1, col2 = st.columns(2)
        with col1:
            brand = st.selectbox("ThÆ°Æ¡ng hiá»‡u (brand)", options=brand_list)
            model_name = st.selectbox("DÃ²ng xe (model)", options=model_list)
            bike_type = st.selectbox("Loáº¡i xe (bike_type)", options=bike_type_list)
            origin = st.selectbox("Xuáº¥t xá»© (origin)", options=origin_list)
        with col2:
            engine_capacity = st.selectbox("Dung tÃ­ch (engine_capacity)", options=engine_capacity_list)
            registration_year = st.number_input("NÄƒm Ä‘Äƒng kÃ½", min_value=1980, max_value=2025, value=2019)
            mileage_km = st.number_input("Sá»‘ km Ä‘Ã£ Ä‘i", min_value=0, value=10000)
            min_price = st.number_input("Khoáº£ng giÃ¡ min (VND)", min_value=0, value=0)
            max_price = st.number_input("Khoáº£ng giÃ¡ max (VND)", min_value=0, value=0)

        if st.button("Cháº¡y dá»± Ä‘oÃ¡n"):
            if model is None:
                st.error(f"KhÃ´ng tÃ¬m tháº¥y model táº¡i '{MODEL_PATH}'. Vui lÃ²ng Ä‘áº£m báº£o file tá»“n táº¡i.")
            else:
                # create df
                df_in = pd.DataFrame([{ 
                    'brand': brand,
                    'model': model_name,
                    'bike_type': bike_type,
                    'origin': origin,
                    'engine_capacity': engine_capacity,
                    'registration_year': registration_year,
                    'mileage_km': mileage_km,
                    'min_price': min_price if min_price>0 else np.nan,
                    'max_price': max_price if max_price>0 else np.nan
                }])

                # compute age
                current_year = 2025
                df_in['age'] = current_year - pd.to_numeric(df_in['registration_year'], errors='coerce')

                # apply grouping using helpers if available
                if helpers is not None:
                    # brand_grouped
                    if df_in.at[0, 'brand'] in helpers['rare_brands']:
                        df_in['brand_grouped'] = 'HÃ£ng khÃ¡c'
                    else:
                        df_in['brand_grouped'] = df_in['brand']

                    # model_grouped
                    bg = df_in.at[0, 'brand_grouped']
                    rare_models = helpers['model_group_maps'].get(bg, set())
                    if df_in.at[0, 'model'] in rare_models:
                        df_in['model_grouped'] = 'DÃ²ng khÃ¡c'
                    else:
                        df_in['model_grouped'] = df_in['model']

                    # segment
                    df_in['segment'] = df_in['brand_grouped'] + '_' + df_in['model_grouped']

                    # brand_meanprice
                    df_in['brand_meanprice'] = helpers['brand_mean_map'].get(df_in.at[0,'brand'], np.nan)
                else:
                    # fallback simple
                    df_in['brand_grouped'] = df_in['brand']
                    df_in['model_grouped'] = df_in['model']
                    df_in['segment'] = df_in['brand'] + '_' + df_in['model']
                    df_in['brand_meanprice'] = np.nan
                    st.warning("KhÃ´ng tÃ¬m tháº¥y data huáº¥n luyá»‡n (data_motobikes.xlsx). App sáº½ dÃ¹ng fallback â€” brand_meanprice cÃ³ thá»ƒ lÃ  NaN, dá»± Ä‘oÃ¡n cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c.")

                # ensure columns order and types as model training
                cat_cols = ['segment','bike_type','origin','engine_capacity']
                num_cols = ['age','mileage_km','min_price','max_price','brand_meanprice']
                X_pred = df_in[cat_cols + num_cols]

                # predict
                try:
                    log_hat = model.predict(X_pred)
                    price_hat = np.expm1(log_hat)
                    df_in['predicted_price'] = price_hat

                    st.success(f"GiÃ¡ dá»± Ä‘oÃ¡n: {int(price_hat[0]):,} VND")
                    st.dataframe(df_in[['brand','model','bike_type','origin','engine_capacity','predicted_price']]) # chá»‰nh in df á»Ÿ Ä‘Ã¢y

                except Exception as e:
                    st.exception(e)

    else: 
        st.subheader("Upload file Ä‘á»ƒ dá»± Ä‘oÃ¡n nhiá»u xe (Excel/CSV)")
        uploaded_file = st.file_uploader("Chá»n file (xlsx/csv)", type=['xlsx','csv'])

        if uploaded_file is not None:
            # save to temp
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp:
                tmp.write(uploaded_file.getvalue())
                tmp_path = tmp.name

            try:
                # ===============================
                # 1) Load file raw
                # ===============================
                if uploaded_file.name.endswith(".csv"):
                    df_raw = pd.read_csv(tmp_path)
                else:
                    df_raw = pd.read_excel(tmp_path)
                    df_raw = df_raw.rename(columns={
                        'GiÃ¡': 'price',
                        'Khoáº£ng giÃ¡ min': 'min_price',
                        'Khoáº£ng giÃ¡ max': 'max_price',
                        'ThÆ°Æ¡ng hiá»‡u': 'brand',
                        'DÃ²ng xe': 'model',
                        'NÄƒm Ä‘Äƒng kÃ½': 'registration_year',
                        'Sá»‘ Km Ä‘Ã£ Ä‘i': 'mileage_km',
                        'TÃ¬nh tráº¡ng': 'condition',
                        'Loáº¡i xe': 'bike_type',
                        'Dung tÃ­ch xe': 'engine_capacity',
                        'Xuáº¥t xá»©': 'origin',
                        'ChÃ­nh sÃ¡ch báº£o hÃ nh': 'warranty_policy',
                        'Trá»ng lÆ°á»£ng': 'weight'
                    })

                # ===============================
                # 2) Chá»‰ giá»¯ Ä‘Ãºng cÃ¡c cá»™t cáº§n thiáº¿t
                # KHÃ”NG CLEAN ná»¯a Ä‘á»ƒ KHÃ”NG lá»‡ch pipeline nháº­p tay
                # ===============================
                needed_cols = [
                    'brand', 'model', 'bike_type', 'origin', 'engine_capacity',
                    'registration_year', 'mileage_km', 'min_price', 'max_price'
                ]

                df = df_raw[needed_cols].copy()

                # ===============================
                # 3) Chuyá»ƒn NaN min/max vá» NaN (giá»‘ng nháº­p tay)
                # ===============================
                df['min_price'] = df['min_price'].replace(0, np.nan)
                df['max_price'] = df['max_price'].replace(0, np.nan)

                # ===============================
                # 4) TÃ­nh age giá»‘ng há»‡t nháº­p tay
                # ===============================
                current_year = 2025
                df['age'] = current_year - pd.to_numeric(df['registration_year'], errors='coerce')

                # ===============================
                # 5) Apply grouping EXACT nhÆ° nháº­p tay
                # ===============================
                if helpers is not None:
                    # brand_grouped
                    df['brand_grouped'] = df['brand'].apply(
                        lambda b: 'HÃ£ng khÃ¡c' if b in helpers['rare_brands'] else b
                    )

                    # model_grouped theo tá»«ng brand_grouped
                    def map_model(row):
                        bg = row['brand_grouped']
                        rare_models = helpers['model_group_maps'].get(bg, set())
                        return 'DÃ²ng khÃ¡c' if row['model'] in rare_models else row['model']

                    df['model_grouped'] = df.apply(map_model, axis=1)

                    # segment
                    df['segment'] = df['brand_grouped'] + '_' + df['model_grouped']

                    # brand_meanprice
                    df['brand_meanprice'] = df['brand'].map(helpers['brand_mean_map'])

                else:
                    # fallback
                    df['brand_grouped'] = df['brand']
                    df['model_grouped'] = df['model']
                    df['segment'] = df['brand'] + '_' + df['model']
                    df['brand_meanprice'] = np.nan
                    st.warning("KhÃ´ng cÃ³ helpers, dá»± Ä‘oÃ¡n cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c.")

                # ===============================
                # 6) Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ predict
                # ===============================
                cat_cols = ['segment','bike_type','origin','engine_capacity']
                num_cols = ['age','mileage_km','min_price','max_price','brand_meanprice']

                X = df[cat_cols + num_cols]

                # ===============================
                # 7) Predict
                # ===============================
                df['predicted_price'] = np.expm1(model.predict(X))

                # ===============================
                # 8) Show result
                # ===============================
                st.write("Káº¿t quáº£ (10 dÃ²ng Ä‘áº§u):")
                st.dataframe(df.head(10))

                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button("Táº£i káº¿t quáº£ (CSV)", data=csv, file_name="predictions.csv", mime='text/csv')

            except Exception as e:
                st.error(f"Lá»—i xá»­ lÃ½ file: {e}")


# --- ANOMALY PAGE ---
else:
    st.header("PhÃ¡t hiá»‡n xe báº¥t thÆ°á»ng")

    # Táº¡o 2 TAB
    tab_user, tab_admin = st.tabs(["ğŸ‘¤ User kiá»ƒm tra xe", "ğŸ›  Admin kiá»ƒm tra dá»¯ liá»‡u"])

    # ======================================
    # 1) TAB USER
    # ======================================
    with tab_user:

        # st.subheader("Nháº­p tay 1 xe Ä‘á»ƒ kiá»ƒm tra")

        # HÃ m lÆ°u request user vÃ o file Excel
        # def save_user_request(df_input):
        #     save_path = "user_submissions.xlsx"
        #     if os.path.exists(save_path):
        #         old = pd.read_excel(save_path)
        #         new = pd.concat([old, df_input], ignore_index=True)
        #     else:
        #         new = df_input.copy()

        #     new.to_excel(save_path, index=False)

        # HÃ m lÆ°u request user vÃ o file Excel
        def save_user_request(df_input):
            save_path = "user_submissions.xlsx"
            
            # Táº¡o báº£n sao Ä‘á»ƒ trÃ¡nh thay Ä‘á»•i DataFrame gá»‘c (df_in)
            df_save = df_input.copy() 

            # 1. Kiá»ƒm tra xem cá»™t 'post_time' cÃ³ tá»“n táº¡i khÃ´ng
            if 'post_time' in df_save.columns:
                # 2. Náº¿u cá»™t lÃ  timezone-aware (cÃ³ mÃºi giá»), chuyá»ƒn nÃ³ thÃ nh timezone-unaware
                if df_save['post_time'].dt.tz is not None:
                    # .dt.tz_localize(None) sáº½ loáº¡i bá» thÃ´ng tin mÃºi giá» (GMT+7)
                    # Dá»¯ liá»‡u ngÃ y giá» váº«n giá»¯ nguyÃªn giÃ¡ trá»‹ theo giá» Ä‘á»‹a phÆ°Æ¡ng (GMT+7)
                    df_save['post_time'] = df_save['post_time'].dt.tz_localize(None)

            if os.path.exists(save_path):
                old = pd.read_excel(save_path)
                new = pd.concat([old, df_save], ignore_index=True)
            else:
                new = df_save.copy()

            # Äoáº¡n nÃ y sáº½ cháº¡y trÆ¡n tru vÃ¬ cá»™t ngÃ y giá» Ä‘Ã£ lÃ  timezone-unaware
            new.to_excel(save_path, index=False)

        # ============================
        # 1.1 Nháº­p tay
        # ============================
        st.subheader("Nháº­p thÃ´ng tin xe cáº§n rao bÃ¡n")
        col1, col2 = st.columns(2)

        with col1:
            brand = st.selectbox("ThÆ°Æ¡ng hiá»‡u", brand_list)
            model_name = st.selectbox("DÃ²ng xe", model_list)
            bike_type = st.selectbox("Loáº¡i xe", bike_type_list)
            origin = st.selectbox("Xuáº¥t xá»©", origin_list)
            engine_capacity = st.selectbox("Dung tÃ­ch", engine_capacity_list)

        with col2:
            registration_year = st.number_input("NÄƒm Ä‘Äƒng kÃ½", 1980, 2025, 2019)
            mileage_km = st.number_input("Sá»‘ km Ä‘Ã£ Ä‘i", 0, value=10000)
            min_price = st.number_input("Khoáº£ng giÃ¡ min", 0)
            max_price = st.number_input("Khoáº£ng giÃ¡ max", 0)
            price = st.number_input("GiÃ¡ niÃªm yáº¿t", 0, value=20000000)
        
        # ThÃªm ngÃ y giá» Ä‘Äƒng tin
        col_d, col_t = st.columns(2)

        # with col_d:
        #     post_date = st.date_input("NgÃ y Ä‘Äƒng tin", value=pd.Timestamp.now().date())

        # with col_t:
        #     post_time = st.time_input("Giá» Ä‘Äƒng tin", value=pd.Timestamp.now().time())

        # # Gá»™p thÃ nh datetime
        # post_datetime = pd.to_datetime(str(post_date) + " " + str(post_time))

        with col_d:
            # Báº¡n cÃ³ thá»ƒ giá»¯ nguyÃªn giÃ¡ trá»‹ máº·c Ä‘á»‹nh lÃ  giá» hiá»‡n táº¡i
            post_date = st.date_input("NgÃ y Ä‘Äƒng tin", value=pd.Timestamp.now(tz=pytz.timezone('Asia/Ho_Chi_Minh')).date())

        with col_t:
            post_time = st.time_input("Giá» Ä‘Äƒng tin", value=pd.Timestamp.now(tz=pytz.timezone('Asia/Ho_Chi_Minh')).time())

        # Gá»™p thÃ nh datetime vÃ  gÃ¡n mÃºi giá»:
        # 1. Táº¡o Ä‘á»‘i tÆ°á»£ng datetime thÃ´ (naive datetime) tá»« date vÃ  time input
        naive_datetime = pd.to_datetime(str(post_date) + " " + str(post_time))

        # 2. Äá»‹nh nghÄ©a mÃºi giá» Asia/Ho_Chi_Minh (GMT+7)
        vietnam_tz = pytz.timezone('Asia/Ho_Chi_Minh')

        # 3. GÃ¡n mÃºi giá» cho Ä‘á»‘i tÆ°á»£ng datetime
        post_datetime = vietnam_tz.localize(naive_datetime)

        # chuáº©n bá»‹ key cho session_state
        if "last_df_in" not in st.session_state:
            st.session_state["last_df_in"] = None
        if "last_anomaly" not in st.session_state:
            st.session_state["last_anomaly"] = None
        if "checked" not in st.session_state:
            st.session_state["checked"] = False

        if st.button("Kiá»ƒm tra"):
            df_in = pd.DataFrame([{
                "brand": brand,
                "model": model_name,
                "bike_type": bike_type,
                "origin": origin,
                "engine_capacity": engine_capacity,
                "registration_year": registration_year,
                "mileage_km": mileage_km,
                "min_price": min_price,
                "max_price": max_price,
                "price": price
            }])

            df_in["age"] = 2025 - df_in["registration_year"]
            df_in["post_time"] = post_datetime

            # Mapping using helpers
            if helpers is not None:
                if df_in.at[0, 'brand'] in helpers['rare_brands']:
                    df_in['brand_grouped'] = 'HÃ£ng khÃ¡c'
                else:
                    df_in['brand_grouped'] = df_in['brand']

                rare_models = helpers['model_group_maps'].get(df_in.at[0, 'brand_grouped'], set())
                if df_in.at[0, 'model'] in rare_models:
                    df_in['model_grouped'] = 'DÃ²ng khÃ¡c'
                else:
                    df_in['model_grouped'] = df_in['model']

                df_in["segment"] = df_in["brand_grouped"] + "_" + df_in["model_grouped"]
                df_in["brand_meanprice"] = helpers["brand_mean_map"].get(df_in.at[0,"brand"], np.nan)
            else:
                df_in["brand_grouped"] = df_in["brand"]
                df_in["model_grouped"] = df_in["model"]
                df_in["segment"] = df_in["brand"] + "_" + df_in["model"]
                df_in["brand_meanprice"] = np.nan

            try:
                df_all, anomaly = detect_outliers(df_in, model_path=MODEL_PATH, input_is_df=True, helpers=helpers)

                # lÆ°u táº¡m vÃ o session Ä‘á»ƒ dÃ¹ng sau khi user xÃ¡c nháº­n
                st.session_state["last_df_in"] = df_in
                st.session_state["last_anomaly"] = anomaly
                st.session_state["checked"] = True

            except Exception as e:
                st.exception(e)

        # Náº¿u Ä‘Ã£ cÃ³ káº¿t quáº£ kiá»ƒm tra trong session_state thÃ¬ hiá»ƒn thá»‹
        if st.session_state.get("checked", False):
            df_in = st.session_state["last_df_in"]
            anomaly = st.session_state["last_anomaly"]

            if anomaly is None:
                st.info("KhÃ´ng cÃ³ káº¿t quáº£ kiá»ƒm tra.")
            else:
                if len(anomaly) > 0:
                    # xÃ¡c Ä‘á»‹nh reason dá»±a trÃªn score nhÆ° yÃªu cáº§u (model/business)
                    # note: detect_outliers Ä‘Ã£ tÃ­nh score_model_based, score_business_based
                    r = []

                    price = anomaly["price"].iloc[0]
                    resid = anomaly["resid"].iloc[0]
                    p10 = anomaly["p10"].iloc[0]
                    p90 = anomaly["p90"].iloc[0]

                    # TÃ­nh giÃ¡ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n
                    predicted_price = price - resid
                    if predicted_price > 0:
                        diff_pct = resid / predicted_price * 100
                    else:
                        diff_pct = None


                    # ===================================================
                    # 1) LÃ DO Dá»°A TRÃŠN ÄIá»‚M MÃ” HÃŒNH (score_model_based)
                    # ===================================================
                    # if anomaly["score_model_based"].iloc[0] >= 50:
                    #     r.append("MÃ´ hÃ¬nh Ä‘Ã¡nh giÃ¡ xe cÃ³ dáº¥u hiá»‡u báº¥t thÆ°á»ng")

                    # 1.1) Residual Z-score â€“ giÃ¡ lá»‡ch xa mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n
                    if anomaly["flag_resid"].iloc[0] == 1:
                        if diff_pct is not None:
                            if resid > 0:
                                r.append(
                                    f"GiÃ¡ Ä‘ang CAO hÆ¡n má»©c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n khoáº£ng {diff_pct:.1f}%"
                                )
                            else:
                                r.append(
                                    f"GiÃ¡ Ä‘ang THáº¤P hÆ¡n má»©c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n khoáº£ng {abs(diff_pct):.1f}%"
                                )
                        else:
                            r.append("GiÃ¡ lá»‡ch quÃ¡ xa mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n")

                    # 1.2) GiÃ¡ náº±m ngoÃ i khoáº£ng Minâ€“Max
                    if anomaly["flag_minmax"].iloc[0] == 1:
                        r.append("GiÃ¡ náº±m ngoÃ i khoáº£ng giÃ¡ há»£p lÃ½ (Minâ€“Max)")

                    # 1.3) GiÃ¡ náº±m ngoÃ i phÃ¢n vá»‹ P10â€“P90
                    if anomaly["flag_p10p90"].iloc[0] == 1:
                        if price < p10:
                            r.append("GiÃ¡ thuá»™c nhÃ³m 10% THáº¤P NHáº¤T cá»§a phÃ¢n khÃºc (ráº» báº¥t thÆ°á»ng)")
                        elif price > p90:
                            r.append("GiÃ¡ thuá»™c nhÃ³m 10% CAO NHáº¤T cá»§a phÃ¢n khÃºc (cao báº¥t thÆ°á»ng)")
                        else:
                            r.append("GiÃ¡ náº±m ngoÃ i khoáº£ng P10â€“P90 cá»§a phÃ¢n khÃºc")

                    # 1.4) Báº¥t thÆ°á»ng tá»« mÃ´ hÃ¬nh khÃ´ng giÃ¡m sÃ¡t (Isolation Forest, LOF, KMeans)
                    if anomaly["flag_unsup"].iloc[0] == 1:
                        r.append("MÃ´ hÃ¬nh há»c mÃ¡y khÃ´ng giÃ¡m sÃ¡t phÃ¡t hiá»‡n Ä‘iá»ƒm báº¥t thÆ°á»ng")


                    # ===================================================
                    # 2) LÃ DO THEO LOGIC NGHIá»†P Vá»¤ (score_business_based)
                    # ===================================================
                    if anomaly["flag_mileage_low"].iloc[0] == 1:
                        r.append("Sá»‘ km Ä‘Ã£ Ä‘i THáº¤P báº¥t thÆ°á»ng so vá»›i tuá»•i xe")

                    if anomaly["flag_mileage_high"].iloc[0] == 1:
                        r.append("Sá»‘ km Ä‘Ã£ Ä‘i CAO báº¥t thÆ°á»ng so vá»›i tuá»•i xe")


                    # ===================================================
                    # 3) Xá»¬ LÃ Káº¾T QUáº¢ CUá»I
                    # ===================================================
                    # reason_text = " + ".join(r) if r else "KhÃ´ng xÃ¡c Ä‘á»‹nh nguyÃªn nhÃ¢n"

                    st.error("ğŸš¨ Há»‡ thá»‘ng phÃ¡t hiá»‡n bÃ i Ä‘Äƒng cÃ³ dáº¥u hiá»‡u Báº¤T THÆ¯á»œNG")

                    if r:
                        st.markdown(
                            "**NguyÃªn nhÃ¢n chi tiáº¿t:**\n"
                            + "\n".join([f"- {reason}" for reason in r])
                        )
                    else:
                        st.markdown("KhÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c nguyÃªn nhÃ¢n.")
                    # st.dataframe(anomaly)

                    # há»i user: cÃ³ muá»‘n Ä‘Äƒng khÃ´ng? + nÃºt xÃ¡c nháº­n lÆ°u
                    choice = st.radio("Xe nÃ y báº¥t thÆ°á»ng, báº¡n váº«n muá»‘n Ä‘Äƒng tin khÃ´ng?", ["KhÃ´ng", "CÃ³"], horizontal=True, key="confirm_post_radio")

                    if st.button("XÃ¡c nháº­n"):
                        if choice == "CÃ³":
                            # chuáº©n bá»‹ báº£n lÆ°u: loáº¡i bá» cá»™t ná»™i bá»™ trÆ°á»›c khi lÆ°u
                            # df_save = df_in.copy()
                            # cols_to_drop = ["brand_grouped", "model_grouped", "segment", "brand_meanprice"]
                            # df_save = df_save.drop(columns=[c for c in cols_to_drop if c in df_save.columns])
                            save_user_request(df_in) # save Ä‘á»§ thÃ´ng tin
                            st.success("ÄÃ£ Ä‘Äƒng tin.")
                            # reset flags
                            st.session_state["last_df_in"] = None
                            st.session_state["last_anomaly"] = None
                            st.session_state["checked"] = False
                        else:
                            st.info("Báº¡n Ä‘Ã£ chá»n khÃ´ng Ä‘Äƒng tin nÃ y.")
                            # reset session
                            st.session_state["last_df_in"] = None
                            st.session_state["last_anomaly"] = None
                            st.session_state["checked"] = False

                else:
                    st.success("ThÃ´ng tin Ä‘Äƒng há»£p lá»‡.")
                    # Show nÃºt lÆ°u náº¿u user muá»‘n (optional) â€” tá»± lÆ°u hoáº·c cho user báº¥m
                    if st.button("ÄÄƒng tin"):
                        # df_save = df_in.copy()
                        # cols_to_drop = ["brand_grouped", "model_grouped", "segment", "brand_meanprice"]
                        # df_save = df_save.drop(columns=[c for c in cols_to_drop if c in df_save.columns])
                        save_user_request(df_in)
                        st.success("ÄÃ£ Ä‘Äƒng tin.")
                        st.session_state["last_df_in"] = None
                        st.session_state["last_anomaly"] = None
                        st.session_state["checked"] = False




    # ======================================
    # 2) TAB ADMIN
    # ======================================
    with tab_admin:

        st.subheader("Cháº¿ Ä‘á»™ kiá»ƒm tra dÃ nh cho Admin")

        mode_admin = st.radio(
            "Chá»n cÃ¡ch kiá»ƒm tra:",
            ["Dá»¯ liá»‡u user nháº­p hÃ´m nay", "Upload file"],
            horizontal=True
        )

        save_path = "user_submissions.xlsx"

        # ============================================================
        # MODE 1: KIá»‚M TRA Dá»® LIá»†U USER NHáº¬P HÃ”M NAY
        # ============================================================
        if mode_admin == "Dá»¯ liá»‡u user nháº­p hÃ´m nay":

            st.subheader("Danh sÃ¡ch tin user Ä‘Ã£ gá»­i")

            if os.path.exists(save_path):
                df_user = pd.read_excel(save_path)

                cols_to_hide = ["brand_grouped", "model_grouped", "segment", "brand_meanprice"]
                df_user_display = df_user.drop(columns=[c for c in cols_to_hide if c in df_user.columns])

                st.dataframe(df_user_display.sort_values(by='post_time', ascending=False))

                if st.button("Cháº¡y kiá»ƒm tra báº¥t thÆ°á»ng (User submissions)"):
                    try:
                        df_all, anomaly = detect_outliers(
                            df_user,
                            model_path=MODEL_PATH,
                            input_is_df=True,
                            helpers=helpers
                        )

                        st.success(f"PhÃ¡t hiá»‡n {len(anomaly)} báº¥t thÆ°á»ng")
                        anomaly_print = anomaly.copy()
                        cols_to_drop = ['brand_grouped', 'model_grouped', 'segment', 'brand_meanprice','price_hat','resid','resid_median','resid_std','resid_z','flag_resid','p10','p90'
]
                        anomaly_print = anomaly_print.drop(columns=[c for c in cols_to_drop if c in anomaly_print.columns])
                        st.dataframe(anomaly_print.sort_values(by='post_time', ascending=False).head(20))

                        # === Báº®T Äáº¦U THÃŠM NÃšT Táº¢I XUá»NG ===
                        if len(anomaly) > 0:
                            # 1. Táº¡o tÃªn file cÃ³ ngÃ y giá»
                            now = datetime.now().strftime("%Y%m%d_%H%M%S")
                            file_name = f"anomaly_detection_user_{now}.csv"
                            
                            # 2. Chuyá»ƒn DataFrame sang CSV
                            # Loáº¡i bá» mÃºi giá» khá»i cá»™t 'post_time' trÆ°á»›c khi táº£i xuá»‘ng náº¿u cáº§n (Ä‘áº£m báº£o khÃ´ng lá»—i)
                            df_output = anomaly_print.copy()
                            if 'post_time' in df_output.columns and df_output['post_time'].dt.tz is not None:
                                df_output['post_time'] = df_output['post_time'].dt.tz_localize(None)

                            csv = df_output.to_csv(index=False).encode('utf-8')
                            
                            # 3. Táº¡o nÃºt táº£i xuá»‘ng
                            st.download_button(
                                label="Táº£i káº¿t quáº£ báº¥t thÆ°á»ng (CSV)",
                                data=csv,
                                file_name=file_name,
                                mime='text/csv'
                            )
                        # === Káº¾T THÃšC THÃŠM NÃšT Táº¢I XUá»NG ===

                    except Exception as e:
                        st.exception(e)

            else:
                st.info("âš  ChÆ°a cÃ³ user nÃ o gá»­i dá»¯ liá»‡u.")


        # ============================================================
        # MODE 2: ADMIN UPLOAD FILE KIá»‚M TRA
        # ============================================================
        else:
            st.subheader("Upload file Ä‘á»ƒ Admin kiá»ƒm tra")

            file_admin = st.file_uploader(
                "Chá»n file dá»¯ liá»‡u cáº§n kiá»ƒm tra (xlsx/csv)",
                type=["xlsx", "csv"],
                key="admin_upload_file"
            )

            if st.button("Cháº¡y kiá»ƒm tra file Admin"):
                if file_admin is None:
                    st.error("Vui lÃ²ng upload file trÆ°á»›c!")
                else:
                    with tempfile.NamedTemporaryFile(
                        delete=False,
                        suffix=os.path.splitext(file_admin.name)[1]
                    ) as tmp:
                        tmp.write(file_admin.getvalue())
                        excel_path = tmp.name

                    try:
                        df_in = preprocess_motobike_data(excel_path)
                        df_all, anomaly = detect_outliers(
                            df_in, 
                            model_path=MODEL_PATH, 
                            input_is_df=True, 
                            helpers=helpers
                        )

                        st.success(
                            f"HoÃ n táº¥t kiá»ƒm tra. Tá»•ng {len(df_in)} báº£n ghi â€” phÃ¡t hiá»‡n {len(anomaly)} báº¥t thÆ°á»ng."
                        )
                        # st.dataframe(anomaly.head(20))
                        anomaly_print = anomaly.copy()
                        cols_to_drop = ['brand_grouped', 'model_grouped', 'segment', 'brand_meanprice','price_hat','resid','resid_median','resid_std','resid_z','flag_resid','p10','p90'
]
                        anomaly_print = anomaly_print.drop(columns=[c for c in cols_to_drop if c in anomaly_print.columns])
                        st.dataframe(anomaly_print.head(20))

                        # === Báº®T Äáº¦U THÃŠM NÃšT Táº¢I XUá»NG ===
                        if len(anomaly) > 0:
                            # 1. Táº¡o tÃªn file cÃ³ ngÃ y giá»
                            now = datetime.now().strftime("%Y%m%d_%H%M%S")
                            file_name = f"anomaly_detection_admin_{now}.csv"
                            
                            # 2. Chuyá»ƒn DataFrame sang CSV
                            df_output = anomaly_print.copy()
                            # Náº¿u cá»™t post_time cÃ³, hÃ£y loáº¡i bá» mÃºi giá» (Ä‘á»ƒ trÃ¡nh lá»—i)
                            if 'post_time' in df_output.columns and df_output['post_time'].dt.tz is not None:
                                df_output['post_time'] = df_output['post_time'].dt.tz_localize(None)

                            csv = df_output.to_csv(index=False).encode('utf-8')
                            
                            # 3. Táº¡o nÃºt táº£i xuá»‘ng
                            st.download_button(
                                label="Táº£i káº¿t quáº£ báº¥t thÆ°á»ng (CSV)",
                                data=csv,
                                file_name=file_name,
                                mime='text/csv'
                            )
                        # === Káº¾T THÃšC THÃŠM NÃšT Táº¢I XUá»NG ===

                    except Exception as e:
                        st.exception(e)



st.sidebar.markdown("---")
# st.sidebar.markdown("""
# ### ThÃ nh viÃªn nhÃ³m 6:
# 1. VÅ© Thá»‹ Ngá»c Anh
# 2. Nguyá»…n Pháº¡m Quá»³nh Anh
# """)
st.sidebar.markdown("á»¨ng dá»¥ng cho phÃ©p: 1) Dá»± Ä‘oÃ¡n giÃ¡ xe mÃ¡y 2) PhÃ¡t hiá»‡n xe báº¥t thÆ°á»ng (nháº­p tay hoáº·c upload file)")
